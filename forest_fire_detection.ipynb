{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsBaRNqKKz1O"
      },
      "source": [
        "Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_CT01QxvLsng",
        "outputId": "c2c6c747-5421-40ba-88b8-f957aaf156f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy42K9XmDtAp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPi3iqlcMd3g"
      },
      "source": [
        "Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIwBO6fYMHrR",
        "outputId": "cb1d6da8-42e5-432a-bca6-5b3aea015ac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eip5YuxLMM9X",
        "outputId": "22bf1099-96f8-45c4-b2da-8b5c9c3760e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alik05/forest-fire-dataset\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading forest-fire-dataset.zip to /content/dataset\n",
            " 98% 139M/142M [00:01<00:00, 103MB/s] \n",
            "100% 142M/142M [00:01<00:00, 82.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d alik05/forest-fire-dataset -p /content/dataset --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRJ6lhEsK4S8"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aemN70DEF0BE"
      },
      "outputs": [],
      "source": [
        "fire_images_path = '/content/dataset/Forest Fire Dataset/Training/fire'\n",
        "non_fire_images_path = '/content/dataset/Forest Fire Dataset/Training/nofire'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93AuHNoEMzLT"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir, target_size=(250, 250)):\n",
        "    # Initialize empty lists to store images and labels\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    categories = os.listdir(data_dir)\n",
        "\n",
        "    for category in categories:\n",
        "        # Path to the category directory\n",
        "        category_dir = os.path.join(data_dir, category)\n",
        "        # Get the label (0 for 'nofire' and 1 for 'fire')\n",
        "        label = 1 if category == 'fire' else 0\n",
        "\n",
        "\n",
        "        for img_file in os.listdir(category_dir):\n",
        "            # Read the image\n",
        "            img_path = os.path.join(category_dir, img_file)\n",
        "            img = cv2.imread(img_path)\n",
        "            # Resize the image to the target size\n",
        "            img = cv2.resize(img, target_size)\n",
        "            # Normalize the image pixels to be in the range [0, 1]\n",
        "            img = img.astype('float32') / 255.0\n",
        "            # Append the image and label to the data lists\n",
        "            data.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11E74JXDNa2B",
        "outputId": "023a3576-69ed-465f-9672-269ec76e1a68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: (1216, 250, 250, 3)\n",
            "Validation data shape: (304, 250, 250, 3)\n"
          ]
        }
      ],
      "source": [
        "train_data, train_labels = load_data('/content/dataset/Forest Fire Dataset/Training')\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Validation data shape:\", val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Dtn6iQdONFu"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "val_labels = to_categorical(val_labels, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8QmJ4FfPI7Y",
        "outputId": "6473e9b2-964e-4153-bd6d-26398da9ca02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 248, 248, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 248, 248, 32)      128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 123, 123, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 123, 123, 64)      256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 61, 61, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 59, 59, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 59, 59, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 29, 29, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 27, 27, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 27, 27, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 13, 13, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 11, 11, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 11, 11, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 5, 5, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1638656   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2177602 (8.31 MB)\n",
            "Trainable params: 2176386 (8.30 MB)\n",
            "Non-trainable params: 1216 (4.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "epochs = 25\n",
        "input_shape = (250, 250, 3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),strides=(1, 1), activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),strides=(2, 2), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3),strides=(1, 1), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add dropout layer for regularization\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flatten the output\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "learning_rate = 0.0001\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdUh4BRkQXok",
        "outputId": "6db421f8-e7ed-4c0a-8781-afa01807c4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "38/38 [==============================] - 242s 6s/step - loss: 1.3559 - accuracy: 0.8923 - val_loss: 0.9366 - val_accuracy: 0.8125\n",
            "Epoch 2/25\n",
            "38/38 [==============================] - 247s 7s/step - loss: 1.0016 - accuracy: 0.9235 - val_loss: 0.9032 - val_accuracy: 0.7993\n",
            "Epoch 3/25\n",
            "38/38 [==============================] - 243s 6s/step - loss: 0.7624 - accuracy: 0.9424 - val_loss: 0.9982 - val_accuracy: 0.7171\n",
            "Epoch 4/25\n",
            "38/38 [==============================] - 247s 7s/step - loss: 0.7608 - accuracy: 0.9359 - val_loss: 0.7955 - val_accuracy: 0.8322\n",
            "Epoch 5/25\n",
            "38/38 [==============================] - 246s 6s/step - loss: 1.0322 - accuracy: 0.9400 - val_loss: 1.2217 - val_accuracy: 0.6875\n",
            "Epoch 6/25\n",
            "38/38 [==============================] - 254s 7s/step - loss: 0.7011 - accuracy: 0.9482 - val_loss: 2.5980 - val_accuracy: 0.5230\n",
            "Epoch 7/25\n",
            "38/38 [==============================] - 264s 7s/step - loss: 0.6145 - accuracy: 0.9572 - val_loss: 2.8263 - val_accuracy: 0.5526\n",
            "Epoch 8/25\n",
            "38/38 [==============================] - 249s 7s/step - loss: 0.5400 - accuracy: 0.9696 - val_loss: 0.7593 - val_accuracy: 0.8684\n",
            "Epoch 9/25\n",
            "38/38 [==============================] - 249s 7s/step - loss: 0.5014 - accuracy: 0.9630 - val_loss: 0.6268 - val_accuracy: 0.9013\n",
            "Epoch 10/25\n",
            "38/38 [==============================] - 244s 6s/step - loss: 0.4807 - accuracy: 0.9597 - val_loss: 0.5774 - val_accuracy: 0.9079\n",
            "Epoch 11/25\n",
            "38/38 [==============================] - 247s 6s/step - loss: 0.4140 - accuracy: 0.9696 - val_loss: 0.5928 - val_accuracy: 0.8651\n",
            "Epoch 12/25\n",
            "38/38 [==============================] - 248s 7s/step - loss: 0.3885 - accuracy: 0.9688 - val_loss: 0.4315 - val_accuracy: 0.9507\n",
            "Epoch 13/25\n",
            "38/38 [==============================] - 247s 7s/step - loss: 0.3563 - accuracy: 0.9803 - val_loss: 0.3849 - val_accuracy: 0.9638\n",
            "Epoch 14/25\n",
            "38/38 [==============================] - 251s 7s/step - loss: 0.3210 - accuracy: 0.9803 - val_loss: 0.4283 - val_accuracy: 0.9375\n",
            "Epoch 15/25\n",
            "38/38 [==============================] - 256s 7s/step - loss: 0.2903 - accuracy: 0.9819 - val_loss: 0.3334 - val_accuracy: 0.9737\n",
            "Epoch 16/25\n",
            "38/38 [==============================] - 257s 7s/step - loss: 0.2989 - accuracy: 0.9811 - val_loss: 0.4255 - val_accuracy: 0.9605\n",
            "Epoch 17/25\n",
            "38/38 [==============================] - 247s 7s/step - loss: 0.2764 - accuracy: 0.9811 - val_loss: 0.4087 - val_accuracy: 0.9572\n",
            "Epoch 18/25\n",
            "38/38 [==============================] - 251s 7s/step - loss: 0.2462 - accuracy: 0.9893 - val_loss: 0.3653 - val_accuracy: 0.9605\n",
            "Epoch 19/25\n",
            "38/38 [==============================] - 249s 7s/step - loss: 0.2513 - accuracy: 0.9819 - val_loss: 0.3151 - val_accuracy: 0.9770\n",
            "Epoch 20/25\n",
            "38/38 [==============================] - 252s 7s/step - loss: 0.2370 - accuracy: 0.9844 - val_loss: 0.3413 - val_accuracy: 0.9507\n",
            "Epoch 21/25\n",
            "38/38 [==============================] - 251s 7s/step - loss: 0.2132 - accuracy: 0.9885 - val_loss: 0.2855 - val_accuracy: 0.9704\n",
            "Epoch 22/25\n",
            "38/38 [==============================] - 252s 7s/step - loss: 0.2037 - accuracy: 0.9844 - val_loss: 0.2992 - val_accuracy: 0.9737\n",
            "Epoch 23/25\n",
            "38/38 [==============================] - 254s 7s/step - loss: 0.1990 - accuracy: 0.9868 - val_loss: 0.2838 - val_accuracy: 0.9803\n",
            "Epoch 24/25\n",
            "38/38 [==============================] - 248s 7s/step - loss: 0.1923 - accuracy: 0.9860 - val_loss: 0.2973 - val_accuracy: 0.9770\n",
            "Epoch 25/25\n",
            "38/38 [==============================] - 251s 7s/step - loss: 0.1767 - accuracy: 0.9893 - val_loss: 0.2835 - val_accuracy: 0.9539\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=25,\n",
        "    batch_size=32,\n",
        "    validation_data=(val_data, val_labels)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-CHpgHuqklP",
        "outputId": "3bebde06-fd17-4104-bf51-50524d78cc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.2835243344306946\n",
            "Validation accuracy: 0.9539473652839661\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on validation data\n",
        "score = model.evaluate(val_data, val_labels, verbose=1)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZB91-FOmIqp"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21LlX2I4gvbe"
      },
      "outputs": [],
      "source": [
        "def load_test_data(data_dir, target_size=(250, 250)):\n",
        "    # Initialize empty lists to store images and labels\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for img_file in os.listdir(data_dir):\n",
        "        img_path = os.path.join(data_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        # Resize the image to the target size\n",
        "        img = cv2.resize(img, target_size)\n",
        "        # Normalize the image pixels to be in the range [0, 1]\n",
        "        img = img.astype('float32') / 255.0\n",
        "        # Append the image to the data list\n",
        "        data.append(img)\n",
        "\n",
        "        # Get the label from the filename (0 for 'nofire' and 1 for 'fire')\n",
        "        label = 1 if img_file.startswith('fire') else 0\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "test_data, test_labels = load_test_data('/content/dataset/Forest Fire Dataset/Testing')\n",
        "test_labels = to_categorical(test_labels, num_classes=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jWMX03umz3V"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvdTfzL9mZsF",
        "outputId": "22ee337a-93d1-4d57-fe60-a1839e16040e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 22s 2s/step - loss: 0.3123 - accuracy: 0.9553\n",
            "Test loss: 0.31232190132141113\n",
            "Test accuracy: 0.9552631378173828\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test data\n",
        "score = model.evaluate(test_data, test_labels, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
